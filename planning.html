<!DOCTYPE html><html lang="en" class="light" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Planning - CS/STAT 184: Introduction to Reinforcement Learning</title><meta property="og:title" content="Planning - CS/STAT 184: Introduction to Reinforcement Learning"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/build/_assets/app-BCJ7T4EU.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-C4ZDKLDU.css"/><link rel="stylesheet" href="/myst-theme.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 013.75 6h16.5a.75.75 0 010 1.5H3.75A.75.75 0 013 6.75zM3 12a.75.75 0 01.75-.75h16.5a.75.75 0 010 1.5H3.75A.75.75 0 013 12zm0 5.25a.75.75 0 01.75-.75h16.5a.75.75 0 010 1.5H3.75a.75.75 0 01-.75-.75z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="p-1 mr-3 dark:bg-white dark:rounded"><img src="/build/184-10fe069484708f6514e3854e25d06608.png" class="h-9" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button class="theme rounded-full border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Change theme to dark mode." aria-label="Change theme to dark mode."><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-full w-full p-0.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386l-1.591 1.591M21 12h-2.25m-.386 6.364l-1.591-1.591M12 18.75V21m-4.773-4.227l-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 11-7.5 0 3.75 3.75 0 017.5 0z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="CS/STAT 184: Introduction to Reinforcement Learning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">CS/STAT 184: Introduction to Reinforcement Learning</a><a title="Markov Decision Processes" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/mdps">Markov Decision Processes</a><a title="Linear Quadratic Regulators" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/control">Linear Quadratic Regulators</a><a title="Multi-Armed Bandits" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/bandits">Multi-Armed Bandits</a><a title="Supervised learning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/supervised-learning">Supervised learning</a><a title="Fitted Dynamic Programming Algorithms" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/fitted-dp">Fitted Dynamic Programming Algorithms</a><a title="Policy Optimization" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/pg">Policy Optimization</a><a title="Imitation Learning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/imitation-learning">Imitation Learning</a><a title="Planning" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/planning">Planning</a><a title="Exploration in MDPs" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/exploration">Exploration in MDPs</a><a title="Appendix: Background" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/background">Appendix: Background</a></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/adzcai/cs-stat-184-notes" title="GitHub Repository: adzcai/cs-stat-184-notes" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="inline-block mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block"><title>Jupyter Notebook</title><path d="M20.2 1.7c0 .8-.5 1.4-1.3 1.5-.8 0-1.4-.5-1.5-1.3 0-.8.5-1.4 1.3-1.5.8-.1 1.5.5 1.5 1.3zM12 17.9c-3.7 0-7-1.3-8.7-3.3 1.8 4.8 7.1 7.3 11.9 5.5 2.5-.9 4.5-2.9 5.5-5.5-1.7 2-4.9 3.3-8.7 3.3zM12 5.1c3.7 0 7 1.3 8.7 3.3-1.8-4.8-7.1-7.3-11.9-5.5-2.5.9-4.5 2.9-5.5 5.5 1.7-2 5-3.3 8.7-3.3zM6.9 21.8c.1 1-.7 1.8-1.7 1.9-1 .1-1.8-.7-1.9-1.7 0-1 .7-1.8 1.7-1.9 1-.1 1.8.7 1.9 1.7zM3.7 4.6c-.6 0-1-.4-1-1s.4-1 1-1 1 .4 1 1c0 .5-.4 1-1 1z"></path></svg></div><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 005.25 21h13.5A2.25 2.25 0 0021 18.75V16.5M16.5 12L12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Planning</h1><header class="mt-4 not-prose"><div><span class="font-semibold text-sm inline-block"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3kfop:" data-state="closed">Alexander D. Cai</button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="yYwTU8SW1z" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="introduction" class="relative group"><span class="heading-text">Introduction</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#introduction" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h2 id="monte-carlo-tree-search" class="relative group"><span class="heading-text">Monte Carlo Tree Search</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#monte-carlo-tree-search" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>(INCOMPLETE)</p></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/imitation-learning"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5L3 12m0 0l7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">CS/STAT 184: Introduction to Reinforcement Learning</div>Imitation Learning</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/exploration"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">CS/STAT 184: Introduction to Reinforcement Learning</div>Exploration in MDPs</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5L21 12m0 0l-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((o,u)=>{if(!window.history.state||!window.history.state.key){let f=Math.random().toString(32).slice(2);window.history.replaceState({key:f},"")}try{let d=JSON.parse(sessionStorage.getItem(o)||"{}")[u||window.history.state.key];typeof d=="number"&&window.scrollTo(0,d)}catch(f){console.error(f),sessionStorage.removeItem(o)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-QAC4OMCW.js"/><link rel="modulepreload" href="/build/_shared/chunk-ELJFAI6P.js"/><link rel="modulepreload" href="/build/_shared/chunk-XJN3BT5Q.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-K5W6CIRR.js"/><link rel="modulepreload" href="/build/_shared/chunk-YAIQ7LUU.js"/><link rel="modulepreload" href="/build/_shared/chunk-HTHE5KDW.js"/><link rel="modulepreload" href="/build/_shared/chunk-YOTPU7U7.js"/><link rel="modulepreload" href="/build/_shared/chunk-QB27XQSF.js"/><link rel="modulepreload" href="/build/_shared/chunk-JOLZ6LZB.js"/><link rel="modulepreload" href="/build/_shared/chunk-MITWS4PZ.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-FSSJOMYR.js"/><link rel="modulepreload" href="/build/_shared/chunk-TEYZXLTV.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-5DLIE3NT.js"/><link rel="modulepreload" href="/build/_shared/chunk-M2HO7LAT.js"/><link rel="modulepreload" href="/build/routes/$-7SLCSLL3.js"/><script>window.__remixContext = {"url":"/planning","state":{"loaderData":{"root":{"theme":"light","config":{"options":{"logo":"/build/184-10fe069484708f6514e3854e25d06608.png"},"myst":"1.3.7","nav":[],"actions":[],"projects":[{"bibliography":["/Users/adzcai/Developer/cs-stat-184-notes/book/shared/references.bib"],"math":{"\\E":{"macro":"\\mathop{\\mathbb{E}}"},"\\pr":{"macro":"\\mathop{\\mathbb{P}}"},"\\kl":{"macro":"\\mathrm{KL}\\left(#1\\parallel#2\\right)"},"\\ind":{"macro":"\\mathbf{1}\\left\\{#1\\right\\}"},"\\hi":{"macro":"h"},"\\hor":{"macro":"H"},"\\st":{"macro":"s"},"\\act":{"macro":"a"}},"exports":[],"title":"CS/STAT 184: Introduction to Reinforcement Learning","authors":[{"nameParsed":{"literal":"Alexander D. Cai","given":"Alexander D.","family":"Cai"},"name":"Alexander D. Cai","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/adzcai/cs-stat-184-notes","toc":[{"file":"index.md"},{"file":"mdps.md"},{"file":"control.md"},{"file":"bandits.md"},{"file":"supervised_learning.md"},{"file":"fitted_dp.md"},{"file":"pg.md"},{"file":"imitation_learning.md"},{"file":"planning.md"},{"file":"exploration.md"},{"file":"background.md"}],"index":"index","pages":[{"slug":"mdps","title":"Markov Decision Processes","description":"","date":"","thumbnail":"/build/deterministic_policy-9d0b50d69541007293ead345d987b682.png","thumbnailOptimized":"/build/deterministic_policy-9d0b50d69541007293ead345d987b682.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"control","title":"Linear Quadratic Regulators","description":"","date":"","thumbnail":"/build/rubiks_cube-5d86d5b19a044eede0a3801e51b37815.jpg","thumbnailOptimized":"/build/rubiks_cube-5d86d5b19a044eede0a3801e51b37815.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"bandits","title":"Multi-Armed Bandits","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"supervised-learning","title":"Supervised learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"fitted-dp","title":"Fitted Dynamic Programming Algorithms","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"pg","title":"Policy Optimization","description":"","date":"","thumbnail":"/build/npg_line-18dfc6d5286c25a94643b5e115d15484.png","thumbnailOptimized":"/build/npg_line-18dfc6d5286c25a94643b5e115d15484.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"imitation-learning","title":"Imitation Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"planning","title":"Planning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"exploration","title":"Exploration in MDPs","description":"","date":"","thumbnail":"/build/sparse_reward_mdp-d4beda7e57ed42a0bbe96cfa6c5ecbbe.png","thumbnailOptimized":"/build/sparse_reward_mdp-d4beda7e57ed42a0bbe96cfa6c5ecbbe.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"background","title":"Appendix: Background","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"options":{"logo":"/build/184-10fe069484708f6514e3854e25d06608.png"},"myst":"1.3.7","nav":[],"actions":[],"projects":[{"bibliography":["/Users/adzcai/Developer/cs-stat-184-notes/book/shared/references.bib"],"math":{"\\E":{"macro":"\\mathop{\\mathbb{E}}"},"\\pr":{"macro":"\\mathop{\\mathbb{P}}"},"\\kl":{"macro":"\\mathrm{KL}\\left(#1\\parallel#2\\right)"},"\\ind":{"macro":"\\mathbf{1}\\left\\{#1\\right\\}"},"\\hi":{"macro":"h"},"\\hor":{"macro":"H"},"\\st":{"macro":"s"},"\\act":{"macro":"a"}},"exports":[],"title":"CS/STAT 184: Introduction to Reinforcement Learning","authors":[{"nameParsed":{"literal":"Alexander D. Cai","given":"Alexander D.","family":"Cai"},"name":"Alexander D. Cai","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/adzcai/cs-stat-184-notes","toc":[{"file":"index.md"},{"file":"mdps.md"},{"file":"control.md"},{"file":"bandits.md"},{"file":"supervised_learning.md"},{"file":"fitted_dp.md"},{"file":"pg.md"},{"file":"imitation_learning.md"},{"file":"planning.md"},{"file":"exploration.md"},{"file":"background.md"}],"index":"index","pages":[{"slug":"mdps","title":"Markov Decision Processes","description":"","date":"","thumbnail":"/build/deterministic_policy-9d0b50d69541007293ead345d987b682.png","thumbnailOptimized":"/build/deterministic_policy-9d0b50d69541007293ead345d987b682.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"control","title":"Linear Quadratic Regulators","description":"","date":"","thumbnail":"/build/rubiks_cube-5d86d5b19a044eede0a3801e51b37815.jpg","thumbnailOptimized":"/build/rubiks_cube-5d86d5b19a044eede0a3801e51b37815.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"bandits","title":"Multi-Armed Bandits","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"supervised-learning","title":"Supervised learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"fitted-dp","title":"Fitted Dynamic Programming Algorithms","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"pg","title":"Policy Optimization","description":"","date":"","thumbnail":"/build/npg_line-18dfc6d5286c25a94643b5e115d15484.png","thumbnailOptimized":"/build/npg_line-18dfc6d5286c25a94643b5e115d15484.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"imitation-learning","title":"Imitation Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"planning","title":"Planning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"exploration","title":"Exploration in MDPs","description":"","date":"","thumbnail":"/build/sparse_reward_mdp-d4beda7e57ed42a0bbe96cfa6c5ecbbe.png","thumbnailOptimized":"/build/sparse_reward_mdp-d4beda7e57ed42a0bbe96cfa6c5ecbbe.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"background","title":"Appendix: Background","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"kind":"Notebook","sha256":"fb8bf96722ee4284b42fe60df752d45b6602d07f22e250964563bbf0157ab39a","slug":"planning","location":"/planning.md","dependencies":[],"frontmatter":{"title":"Planning","kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"jupytext":{"text_representation":{"extension":".md","format_name":"myst","format_version":"0.13","jupytext_version":"1.16.2"}},"content_includes_title":false,"authors":[{"nameParsed":{"literal":"Alexander D. Cai","given":"Alexander D.","family":"Cai"},"name":"Alexander D. Cai","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/adzcai/cs-stat-184-notes","math":{"\\E":{"macro":"\\mathop{\\mathbb{E}}"},"\\pr":{"macro":"\\mathop{\\mathbb{P}}"},"\\kl":{"macro":"\\mathrm{KL}\\left(#1\\parallel#2\\right)"},"\\ind":{"macro":"\\mathbf{1}\\left\\{#1\\right\\}"},"\\hi":{"macro":"h"},"\\hor":{"macro":"H"},"\\st":{"macro":"s"},"\\act":{"macro":"a"}},"exports":[{"format":"md","filename":"planning.md","url":"/build/planning-01768130191cacdd6ad9a7a971d538e9.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Introduction","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"qgHNa9IFT8"}],"identifier":"introduction","label":"Introduction","html_id":"introduction","implicit":true,"key":"H1h5msZPEU"},{"type":"heading","depth":2,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Monte Carlo Tree Search","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"x97VQ0bcju"}],"identifier":"monte-carlo-tree-search","label":"Monte Carlo Tree Search","html_id":"monte-carlo-tree-search","implicit":true,"key":"T6rgcifl6W"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"(INCOMPLETE)","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"ndVgPzexAe"}],"key":"XPnnOZszTH"}],"key":"yYwTU8SW1z"}],"key":"sUuee5tdmE"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Imitation Learning","url":"/imitation-learning","group":"CS/STAT 184: Introduction to Reinforcement Learning"},"next":{"title":"Exploration in MDPs","url":"/exploration","group":"CS/STAT 184: Introduction to Reinforcement Learning"}}},"domain":"http://localhost:3000"},"project":{"bibliography":["/Users/adzcai/Developer/cs-stat-184-notes/book/shared/references.bib"],"math":{"\\E":{"macro":"\\mathop{\\mathbb{E}}"},"\\pr":{"macro":"\\mathop{\\mathbb{P}}"},"\\kl":{"macro":"\\mathrm{KL}\\left(#1\\parallel#2\\right)"},"\\ind":{"macro":"\\mathbf{1}\\left\\{#1\\right\\}"},"\\hi":{"macro":"h"},"\\hor":{"macro":"H"},"\\st":{"macro":"s"},"\\act":{"macro":"a"}},"exports":[],"title":"CS/STAT 184: Introduction to Reinforcement Learning","authors":[{"nameParsed":{"literal":"Alexander D. Cai","given":"Alexander D.","family":"Cai"},"name":"Alexander D. Cai","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/adzcai/cs-stat-184-notes","toc":[{"file":"index.md"},{"file":"mdps.md"},{"file":"control.md"},{"file":"bandits.md"},{"file":"supervised_learning.md"},{"file":"fitted_dp.md"},{"file":"pg.md"},{"file":"imitation_learning.md"},{"file":"planning.md"},{"file":"exploration.md"},{"file":"background.md"}],"index":"index","pages":[{"slug":"mdps","title":"Markov Decision Processes","description":"","date":"","thumbnail":"/build/deterministic_policy-9d0b50d69541007293ead345d987b682.png","thumbnailOptimized":"/build/deterministic_policy-9d0b50d69541007293ead345d987b682.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"control","title":"Linear Quadratic Regulators","description":"","date":"","thumbnail":"/build/rubiks_cube-5d86d5b19a044eede0a3801e51b37815.jpg","thumbnailOptimized":"/build/rubiks_cube-5d86d5b19a044eede0a3801e51b37815.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"bandits","title":"Multi-Armed Bandits","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"supervised-learning","title":"Supervised learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"fitted-dp","title":"Fitted Dynamic Programming Algorithms","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"pg","title":"Policy Optimization","description":"","date":"","thumbnail":"/build/npg_line-18dfc6d5286c25a94643b5e115d15484.png","thumbnailOptimized":"/build/npg_line-18dfc6d5286c25a94643b5e115d15484.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"imitation-learning","title":"Imitation Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"planning","title":"Planning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"exploration","title":"Exploration in MDPs","description":"","date":"","thumbnail":"/build/sparse_reward_mdp-d4beda7e57ed42a0bbe96cfa6c5ecbbe.png","thumbnailOptimized":"/build/sparse_reward_mdp-d4beda7e57ed42a0bbe96cfa6c5ecbbe.webp","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"background","title":"Appendix: Background","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-FD44876C.js";
import * as route0 from "/build/root-5DLIE3NT.js";
import * as route1 from "/build/routes/$-7SLCSLL3.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-QAC4OMCW.js");</script></body></html>